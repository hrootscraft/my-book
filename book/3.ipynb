{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('normalized_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('ChurnLabel', axis=1)\n",
    "y = df['ChurnLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode target variable ('No' -> 0, 'Yes' -> 1)\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as hrootscraft\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as hrootscraft\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "# dagshub.init(repo_owner='hrootscraft', repo_name='my-book', mlflow=True)\n",
    "DAGSHUB_TOKEN = dagshub.auth.get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class CustomPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns_to_drop = ['Country', 'State', 'CustomerID', 'Latitude',\n",
    "                               'Longitude', 'ChurnScore', 'CLTV', \n",
    "                               'ChurnReason', 'ZipCode', 'City']\n",
    "        self.numeric_features = ['TenureMonths', 'MonthlyCharges', 'TotalCharges']\n",
    "        self.categorical_features = None  # Will be set during fit\n",
    "        self.scaler = StandardScaler()\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.encoded_feature_names = None\n",
    "\n",
    "    def _impute_total_charges(self, X):\n",
    "        X_ = X.copy()\n",
    "        for index, row in X_.iterrows():\n",
    "            if math.isnan(row['TotalCharges']):\n",
    "                X_.at[index, 'TotalCharges'] = (\n",
    "                    X_.at[index, 'MonthlyCharges'] * X_.at[index, 'TenureMonths']\n",
    "                )\n",
    "        return X_\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Set categorical features (excluding target)\n",
    "        self.categorical_features = [col for col in X.select_dtypes(include=['object']).columns \n",
    "                                   if col not in self.columns_to_drop + ['ChurnLabel']]\n",
    "        \n",
    "        X_ = X.copy()\n",
    "        X_ = self._impute_total_charges(X_)\n",
    "        X_ = X_.drop(columns=self.columns_to_drop, errors='ignore')\n",
    "        X_['TotalCharges'] = np.log1p(X_['TotalCharges'])\n",
    "        \n",
    "        self.scaler.fit(X_[self.numeric_features])\n",
    "        self.encoder.fit(X_[self.categorical_features])\n",
    "        \n",
    "        self.encoded_feature_names = []\n",
    "        for i, feature in enumerate(self.categorical_features):\n",
    "            feature_categories = self.encoder.categories_[i]\n",
    "            self.encoded_feature_names.extend([f\"{feature}_{cat}\" for cat in feature_categories])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        X_ = self._impute_total_charges(X_)\n",
    "        X_ = X_.drop(columns=self.columns_to_drop, errors='ignore')\n",
    "        X_['TotalCharges'] = np.log1p(X_['TotalCharges'])\n",
    "        \n",
    "        X_scaled = pd.DataFrame(\n",
    "            self.scaler.transform(X_[self.numeric_features]),\n",
    "            columns=self.numeric_features,\n",
    "            index=X_.index\n",
    "        )\n",
    "        \n",
    "        X_encoded = pd.DataFrame(\n",
    "            self.encoder.transform(X_[self.categorical_features]),\n",
    "            columns=self.encoded_feature_names,\n",
    "            index=X_.index\n",
    "        )\n",
    "        \n",
    "        return pd.concat([X_scaled, X_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "import mlflow\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time, os\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Set MLflow tracking URI and credentials\n",
    "MLFLOW_TRACKING_URI = \"https://dagshub.com/hrootscraft/my-book.mlflow\"\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'hrootscraft'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"churn_prediction\")\n",
    "\n",
    "\n",
    "def train_logistic_regression(X_train, X_test, y_train, y_test, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Trains and evaluates the model with cross-validation and hyperparameter tuning\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=\"logistic_regression\"):\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', CustomPreprocessor()),\n",
    "            ('classifier', LogisticRegression())\n",
    "        ])\n",
    "        \n",
    "        # Define parameter grid\n",
    "        param_grid = {\n",
    "            'classifier__C': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4],\n",
    "            'classifier__solver': ['liblinear'],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "        \n",
    "        # Perform GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline, param_grid, \n",
    "            scoring='f1', \n",
    "            cv=cv_folds, \n",
    "            n_jobs=-1, \n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Log best parameters\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        \n",
    "        # Perform cross-validation with best model\n",
    "        cv_results = cross_validate(\n",
    "            grid_search.best_estimator_,\n",
    "            X_train, y_train,\n",
    "            cv=cv_folds,\n",
    "            scoring='f1',\n",
    "            return_train_score=True\n",
    "        )\n",
    "        \n",
    "        # Log cross-validation results\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_results['test_score'].mean())\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_results['test_score'].std())\n",
    "        \n",
    "        # Get predictions on test set\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        # Log metrics\n",
    "        metrics = {\n",
    "            \"test_f1\": f1,\n",
    "            \"true_negatives\": tn,\n",
    "            \"false_positives\": fp,\n",
    "            \"false_negatives\": fn,\n",
    "            \"true_positives\": tp\n",
    "        }\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model\n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=grid_search.best_estimator_,\n",
    "            artifact_path=\"churn_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_test.iloc[0:1],\n",
    "            registered_model_name=\"LogisticRegression\"\n",
    "        )\n",
    "        \n",
    "        t2 = time.time()\n",
    "        print(f\"Training completed in {t2-t1:.2f} seconds\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best CV f1-score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"Test f1-score: {f1:.4f}\")\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(f\"TN: {tn}, FP: {fp}\")\n",
    "        print(f\"FN: {fn}, TP: {tp}\")\n",
    "        \n",
    "        return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rutuja/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'LogisticRegression' already exists. Creating a new version of this model...\n",
      "2024/12/22 17:41:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LogisticRegression, version 6\n",
      "Created version '6' of model 'LogisticRegression'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 25.20 seconds\n",
      "Best parameters: {'classifier__C': 100.0, 'classifier__class_weight': 'balanced', 'classifier__solver': 'liblinear'}\n",
      "Best CV f1-score: 0.6498\n",
      "Test f1-score: 0.6253\n",
      "\n",
      "Confusion Matrix:\n",
      "TN: 756, FP: 279\n",
      "FN: 77, TP: 297\n",
      "🏃 View run logistic_regression at: https://dagshub.com/hrootscraft/my-book.mlflow/#/experiments/0/runs/e5d2f47bda584bf382ae944d0b661299\n",
      "🧪 View experiment at: https://dagshub.com/hrootscraft/my-book.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "logi_model = train_logistic_regression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge_classifier(X_train, X_test, y_train, y_test, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Trains and evaluates Ridge Classifier with cross-validation and hyperparameter tuning\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=\"ridge_classifier\"):\n",
    "        t1 = time.time()\n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', CustomPreprocessor()),\n",
    "            ('classifier', RidgeClassifier())\n",
    "        ])\n",
    "        \n",
    "        # Define parameter grid\n",
    "        param_grid = {\n",
    "            'classifier__alpha': [0.1, 1.0, 10.0, 100.0],\n",
    "            'classifier__class_weight': ['balanced'],\n",
    "            'classifier__solver': ['auto', 'svd', 'cholesky']\n",
    "        }\n",
    "        \n",
    "        # Perform GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline, param_grid,\n",
    "            scoring='f1',\n",
    "            cv=cv_folds,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Rest of the code follows the same pattern as your logistic regression\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        \n",
    "        cv_results = cross_validate(\n",
    "            grid_search.best_estimator_,\n",
    "            X_train, y_train,\n",
    "            cv=cv_folds,\n",
    "            scoring='f1',\n",
    "            return_train_score=True\n",
    "        )\n",
    "        \n",
    "        # Log cross-validation results\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_results['test_score'].mean())\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_results['test_score'].std())\n",
    "        \n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        metrics = {\n",
    "            \"test_f1\": f1,\n",
    "            \"true_negatives\": tn,\n",
    "            \"false_positives\": fp,\n",
    "            \"false_negatives\": fn,\n",
    "            \"true_positives\": tp\n",
    "        }\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=grid_search.best_estimator_,\n",
    "            artifact_path=\"ridge_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_test.iloc[0:1],\n",
    "            registered_model_name=\"RidgeClassifier\"\n",
    "        )\n",
    "        \n",
    "        t2 = time.time()\n",
    "        print(f\"Training completed in {t2-t1:.2f} seconds\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best CV f1-score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"Test f1-score: {f1:.4f}\")\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(f\"TN: {tn}, FP: {fp}\")\n",
    "        print(f\"FN: {fn}, TP: {tp}\")\n",
    "        \n",
    "        return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rutuja/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'RidgeClassifier' already exists. Creating a new version of this model...\n",
      "2024/12/22 17:42:21 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: RidgeClassifier, version 6\n",
      "Created version '6' of model 'RidgeClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 26.72 seconds\n",
      "Best parameters: {'classifier__alpha': 100.0, 'classifier__class_weight': 'balanced', 'classifier__solver': 'auto'}\n",
      "Best CV f1-score: 0.6464\n",
      "Test f1-score: 0.6184\n",
      "\n",
      "Confusion Matrix:\n",
      "TN: 741, FP: 294\n",
      "FN: 75, TP: 299\n",
      "🏃 View run ridge_classifier at: https://dagshub.com/hrootscraft/my-book.mlflow/#/experiments/0/runs/d987da39a0c1498396bee34fa7ab6de2\n",
      "🧪 View experiment at: https://dagshub.com/hrootscraft/my-book.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "ridge_model = train_ridge_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest_classifier(X_train, X_test, y_train, y_test, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Trains and evaluates Random Forest Classifier with cross-validation and hyperparameter tuning\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=\"random_forest_classifier\"):\n",
    "        t1 = time.time()\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', CustomPreprocessor()),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "        \n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [10, 20, 30, None],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__min_samples_leaf': [1, 2, 4],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline, param_grid,\n",
    "            scoring='f1',\n",
    "            cv=cv_folds,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Rest follows the same pattern\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        \n",
    "        cv_results = cross_validate(\n",
    "            grid_search.best_estimator_,\n",
    "            X_train, y_train,\n",
    "            cv=cv_folds,\n",
    "            scoring='f1',\n",
    "            return_train_score=True\n",
    "        )\n",
    "        \n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_results['test_score'].mean())\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_results['test_score'].std())\n",
    "        \n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        metrics = {\n",
    "            \"test_f1\": f1,\n",
    "            \"true_negatives\": tn,\n",
    "            \"false_positives\": fp,\n",
    "            \"false_negatives\": fn,\n",
    "            \"true_positives\": tp\n",
    "        }\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=grid_search.best_estimator_,\n",
    "            artifact_path=\"random_forest_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_test.iloc[0:1],\n",
    "            registered_model_name=\"RandomForestClassifier\"\n",
    "        )\n",
    "        \n",
    "        t2 = time.time()\n",
    "        print(f\"Training completed in {t2-t1:.2f} seconds\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best CV f1-score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"Test f1-score: {f1:.4f}\")\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(f\"TN: {tn}, FP: {fp}\")\n",
    "        print(f\"FN: {fn}, TP: {tp}\")\n",
    "        \n",
    "        return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rutuja/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'RandomForestClassifier' already exists. Creating a new version of this model...\n",
      "2024/12/22 17:47:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: RandomForestClassifier, version 2\n",
      "Created version '2' of model 'RandomForestClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 327.47 seconds\n",
      "Best parameters: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\n",
      "Best CV f1-score: 0.6501\n",
      "Test f1-score: 0.6317\n",
      "\n",
      "Confusion Matrix:\n",
      "TN: 796, FP: 239\n",
      "FN: 91, TP: 283\n",
      "🏃 View run random_forest_classifier at: https://dagshub.com/hrootscraft/my-book.mlflow/#/experiments/0/runs/630bd76fb60c43e4a7f4322241ea58af\n",
      "🧪 View experiment at: https://dagshub.com/hrootscraft/my-book.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "rndf_model = train_random_forest_classifier(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
